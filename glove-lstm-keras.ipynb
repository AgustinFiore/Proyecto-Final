{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Tabla de contenidos\n\n1. [**Importación de librerías**](#1.-Importación-de-librerías)   \n2. [**Cargo los datos**](#2.-Cargo-los-datos) \n3. [**Limpieza de los datos**](#3.-Limpieza-de-los-datos)  \n    3.1 [**Checkeo los duplicados**](#3.1-Checkeo-los-duplicados)   \n    3.2 [**Compruebo si existen reseñas vacías**](#3.2-Compruebo-si-existen-reseñas-vacías)  \n    3.3 [**Distribución de los datos**](#3.3-Distribución-de-los-datos)\n4. [**Preprocesamiento del texto**](#4.-Preprocesamiento-del-texto)  \n5. [**Normalización de los datos**](#5.-Normalización-de-los-datos)    \n    5.1 [**Normalizo el puntaje de las reseñas para que varíe entre 0 y 4**](#5.1-Normalizo-el-puntaje-de-las-reseñas-para-que-varíe-entre-0-y-4)  \n    5.2 [**Elimino columnas que no van a ser utilizadas**](#5.2-Elimino-columnas-que-no-van-a-ser-utilizadas)  \n    5.3 [**Elimino textos que pueden haber quedado vacíos luego de preprocesar el texto**](#5.3-Elimino-textos-que-pueden-haber-quedado-vacíos-luego-de-preprocesar-el-texto)  \n    5.4 [**Separo los datos en dos conjuntos: train y test (80/20)**](#5.4-Separo-los-datos-en-dos-conjuntos:-train-y-test-(80/20))  \n6. [**Creación del modelo**](#6.-Creación-del-modelo)   \n    6.1 [**Uso LSTM bidireccional con Embedding layer**](#6.1-Uso-LSTM-bidireccional-con-Embedding-layer)   \n    6.2 [**Entreno el modelo**](#6.2-Entreno-el-modelo)   ","metadata":{}},{"cell_type":"markdown","source":"### 1. Importación de librerías","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport re\nfrom bs4 import BeautifulSoup\nfrom tqdm import tqdm\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,f1_score, confusion_matrix\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\nfrom keras.models import Model, Sequential\nfrom keras.layers import Convolution1D\nfrom keras import initializers, regularizers, constraints, optimizers, layers","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:55:58.862545Z","iopub.execute_input":"2021-11-18T23:55:58.862919Z","iopub.status.idle":"2021-11-18T23:56:06.666084Z","shell.execute_reply.started":"2021-11-18T23:55:58.86285Z","shell.execute_reply":"2021-11-18T23:56:06.665224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Cargo los datos","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/amazon-product-reviews/Reviews.csv\")\nprint(\"Tamaño de los datos: \", df.shape)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-11-18T23:56:06.667351Z","iopub.execute_input":"2021-11-18T23:56:06.667579Z","iopub.status.idle":"2021-11-18T23:56:12.931038Z","shell.execute_reply.started":"2021-11-18T23:56:06.667538Z","shell.execute_reply":"2021-11-18T23:56:12.930141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:56:12.932359Z","iopub.execute_input":"2021-11-18T23:56:12.932627Z","iopub.status.idle":"2021-11-18T23:56:12.964096Z","shell.execute_reply.started":"2021-11-18T23:56:12.932577Z","shell.execute_reply":"2021-11-18T23:56:12.963123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Limpieza de los datos","metadata":{}},{"cell_type":"markdown","source":"#### 3.1 Checkeo los duplicados","metadata":{}},{"cell_type":"code","source":"df=df.sort_values('ProductId', kind='quicksort', na_position='last')","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:56:12.965797Z","iopub.execute_input":"2021-11-18T23:56:12.966113Z","iopub.status.idle":"2021-11-18T23:56:13.693496Z","shell.execute_reply.started":"2021-11-18T23:56:12.966061Z","shell.execute_reply":"2021-11-18T23:56:13.692546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df.drop_duplicates(subset={\"Text\"}, keep='first', inplace=False)\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:56:13.694844Z","iopub.execute_input":"2021-11-18T23:56:13.695104Z","iopub.status.idle":"2021-11-18T23:56:14.694902Z","shell.execute_reply.started":"2021-11-18T23:56:13.695061Z","shell.execute_reply":"2021-11-18T23:56:14.693652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.2 Compruebo si existen reseñas vacías","metadata":{}},{"cell_type":"code","source":"print(df['Text'].isnull().sum())\ndf['Score'].isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.3 Distribución de los datos","metadata":{}},{"cell_type":"code","source":"df['Score'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:56:14.696617Z","iopub.execute_input":"2021-11-18T23:56:14.69696Z","iopub.status.idle":"2021-11-18T23:56:14.711216Z","shell.execute_reply.started":"2021-11-18T23:56:14.69691Z","shell.execute_reply":"2021-11-18T23:56:14.709154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,7))\nsns.countplot(df['Score'])\nplt.title(\"Distribución de la puntuación\")","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:56:14.713884Z","iopub.execute_input":"2021-11-18T23:56:14.714258Z","iopub.status.idle":"2021-11-18T23:56:15.039022Z","shell.execute_reply.started":"2021-11-18T23:56:14.714186Z","shell.execute_reply":"2021-11-18T23:56:15.037641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Preprocesamiento del texto\n\nA continuación se realizarán distintas operaciones para:\n\n* Remover links de sitios web\n* Remover tags html\n* Descontracturar palabras\n* Remover palabras con números Removing the words with numeric digits\n* Remover caracteres especiales Removing non-word characters\n* Convertir el texto a minúscula\n* Remover las stop words\n* Aplicar lematización","metadata":{}},{"cell_type":"code","source":"def decontract(text):\n    text = re.sub(r\"won\\'t\", \"will not\", text)\n    text = re.sub(r\"can\\'t\", \"can not\", text)\n    text = re.sub(r\"n\\'t\", \" not\", text)\n    text = re.sub(r\"\\'re\", \" are\", text)\n    text = re.sub(r\"\\'s\", \" is\", text)\n    text = re.sub(r\"\\'d\", \" would\", text)\n    text = re.sub(r\"\\'ll\", \" will\", text)\n    text = re.sub(r\"\\'t\", \" not\", text)\n    text = re.sub(r\"\\'ve\", \" have\", text)\n    text = re.sub(r\"\\'m\", \" am\", text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:56:15.040995Z","iopub.execute_input":"2021-11-18T23:56:15.04174Z","iopub.status.idle":"2021-11-18T23:56:15.052316Z","shell.execute_reply.started":"2021-11-18T23:56:15.041583Z","shell.execute_reply":"2021-11-18T23:56:15.051209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nnegative_stop_words = set(word for word in stop_words if \"n't\" in word or 'no' in word)\nstop_words = stop_words - negative_stop_words","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:56:15.05395Z","iopub.execute_input":"2021-11-18T23:56:15.054553Z","iopub.status.idle":"2021-11-18T23:56:15.074317Z","shell.execute_reply.started":"2021-11-18T23:56:15.054485Z","shell.execute_reply":"2021-11-18T23:56:15.072998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lemmatizer = WordNetLemmatizer()\ndef preprocess_text(review):\n    review = re.sub(r\"http\\S+\", \"\", review)             # removing website links\n    review = BeautifulSoup(review, 'lxml').get_text()   # removing html tags\n    review = decontract(review)                         # decontracting\n    review = re.sub(\"\\S*\\d\\S*\", \"\", review).strip()     # removing the words with numeric digits\n    review = re.sub('[^A-Za-z]+', ' ', review)          # removing non-word characters\n    review = review.lower()                             # converting to lower case\n    review = [word for word in review.split(\" \") if not word in stop_words] # removing stop words\n    review = [lemmatizer.lemmatize(token, \"v\") for token in review] #lemmatization\n    review = \" \".join(review)\n    review.strip()\n    return review\ndf['Text'] = df['Text'].apply(lambda x: preprocess_text(x))","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:56:27.85475Z","iopub.execute_input":"2021-11-18T23:56:27.855063Z","iopub.status.idle":"2021-11-19T00:00:28.306042Z","shell.execute_reply.started":"2021-11-18T23:56:27.855014Z","shell.execute_reply":"2021-11-19T00:00:28.305252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Text'].head()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:00:28.308463Z","iopub.execute_input":"2021-11-19T00:00:28.308768Z","iopub.status.idle":"2021-11-19T00:00:28.316625Z","shell.execute_reply.started":"2021-11-19T00:00:28.308714Z","shell.execute_reply":"2021-11-19T00:00:28.3157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5. Normalización de los datos\n\n#### 5.1 Normalizo el puntaje de las reseñas para que varíe entre 0 y 4","metadata":{}},{"cell_type":"code","source":"def normalize(score):\n    return score - 1","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:00:28.318374Z","iopub.execute_input":"2021-11-19T00:00:28.319041Z","iopub.status.idle":"2021-11-19T00:00:28.327654Z","shell.execute_reply.started":"2021-11-19T00:00:28.318976Z","shell.execute_reply":"2021-11-19T00:00:28.326939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Score\"] = df[\"Score\"].apply(normalize)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:00:28.329178Z","iopub.execute_input":"2021-11-19T00:00:28.330036Z","iopub.status.idle":"2021-11-19T00:00:28.460492Z","shell.execute_reply.started":"2021-11-19T00:00:28.329578Z","shell.execute_reply":"2021-11-19T00:00:28.459644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.2 Elimino columnas que no van a ser utilizadas","metadata":{}},{"cell_type":"code","source":"df = df.drop(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time', 'Summary'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:00:28.46428Z","iopub.execute_input":"2021-11-19T00:00:28.464963Z","iopub.status.idle":"2021-11-19T00:00:28.483311Z","shell.execute_reply.started":"2021-11-19T00:00:28.464588Z","shell.execute_reply":"2021-11-19T00:00:28.482171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.3 Elimino textos que pueden haber quedado vacíos luego de preprocesar el texto","metadata":{}},{"cell_type":"code","source":"df['Text'].replace('', np.nan, inplace=True)\ndf.dropna(subset=['Text'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:00:28.485151Z","iopub.execute_input":"2021-11-19T00:00:28.485788Z","iopub.status.idle":"2021-11-19T00:00:28.642233Z","shell.execute_reply.started":"2021-11-19T00:00:28.485622Z","shell.execute_reply":"2021-11-19T00:00:28.641178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:00:28.643553Z","iopub.execute_input":"2021-11-19T00:00:28.643857Z","iopub.status.idle":"2021-11-19T00:00:28.65344Z","shell.execute_reply.started":"2021-11-19T00:00:28.643801Z","shell.execute_reply":"2021-11-19T00:00:28.652315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.4 Separo los datos en dos conjuntos: train y test (80/20)","metadata":{}},{"cell_type":"code","source":"train_df, test_df = train_test_split(df, test_size = 0.2, random_state = 42)\nprint(\"Training data size: \", train_df.shape)\nprint(\"Test data size: \", test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:00:28.654958Z","iopub.execute_input":"2021-11-19T00:00:28.6553Z","iopub.status.idle":"2021-11-19T00:00:28.740977Z","shell.execute_reply.started":"2021-11-19T00:00:28.655243Z","shell.execute_reply":"2021-11-19T00:00:28.740144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6. Creación del modelo","metadata":{}},{"cell_type":"markdown","source":"#### 6.1 Uso LSTM bidireccional con Embedding layer","metadata":{}},{"cell_type":"code","source":"top_words = 6000\ntokenizer = Tokenizer(num_words=top_words)\ntokenizer.fit_on_texts(train_df['Text'])\nlist_tokenized_train = tokenizer.texts_to_sequences(train_df['Text'])\n\nvocab_size = len(tokenizer.word_index) + 1\nmax_review_length = 100\nX_train = pad_sequences(list_tokenized_train, maxlen=max_review_length)\ny_train = train_df['Score']","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:00:28.742203Z","iopub.execute_input":"2021-11-19T00:00:28.742497Z","iopub.status.idle":"2021-11-19T00:00:54.427887Z","shell.execute_reply.started":"2021-11-19T00:00:28.742434Z","shell.execute_reply":"2021-11-19T00:00:54.427028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import array, asarray, zeros\n\nembeddings_dictionary = dict()\n\nglove_file = open('/kaggle/input/glove6b100dtxt/glove.6B.100d.txt', encoding=\"utf8\")\n\nfor line in glove_file:\n    records = line.split()\n    word = records[0]\n    vector_dimensions = asarray(records[1:], dtype='float32')\n    embeddings_dictionary[word] = vector_dimensions\nglove_file.close()\n\nembedding_matrix = zeros((vocab_size, 100))\nfor word, index in tokenizer.word_index.items():\n    embedding_vector = embeddings_dictionary.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[index] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:00:54.42941Z","iopub.execute_input":"2021-11-19T00:00:54.429758Z","iopub.status.idle":"2021-11-19T00:01:07.685683Z","shell.execute_reply.started":"2021-11-19T00:00:54.429702Z","shell.execute_reply":"2021-11-19T00:01:07.684786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Bidirectional\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_review_length))\nmodel.add(Bidirectional(LSTM(100)))\nmodel.add(Dense(5, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:01:07.686885Z","iopub.execute_input":"2021-11-19T00:01:07.687146Z","iopub.status.idle":"2021-11-19T00:01:08.343917Z","shell.execute_reply.started":"2021-11-19T00:01:07.687094Z","shell.execute_reply":"2021-11-19T00:01:08.342775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import plot_model\nplot_model(model, to_file='model_plot4a.png', show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:01:08.346232Z","iopub.execute_input":"2021-11-19T00:01:08.346604Z","iopub.status.idle":"2021-11-19T00:01:08.690299Z","shell.execute_reply.started":"2021-11-19T00:01:08.346533Z","shell.execute_reply":"2021-11-19T00:01:08.689215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\ny_train = keras.utils.to_categorical(y_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:01:08.692111Z","iopub.execute_input":"2021-11-19T00:01:08.692701Z","iopub.status.idle":"2021-11-19T00:01:08.712397Z","shell.execute_reply.started":"2021-11-19T00:01:08.692618Z","shell.execute_reply":"2021-11-19T00:01:08.711203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 6.2 Entreno el modelo","metadata":{}},{"cell_type":"code","source":"history = model.fit(X_train, y_train, batch_size=128, epochs=5, verbose=1, validation_split=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history2 = model.fit(X_train, y_train, batch_size=32, epochs=5, verbose=1, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T22:19:18.08805Z","iopub.execute_input":"2021-11-17T22:19:18.088919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history3 = model.fit(X_train, y_train, batch_size=64, epochs=5, verbose=1, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:01:08.71473Z","iopub.execute_input":"2021-11-19T00:01:08.71522Z","iopub.status.idle":"2021-11-19T01:49:26.767482Z","shell.execute_reply.started":"2021-11-19T00:01:08.715132Z","shell.execute_reply":"2021-11-19T01:49:26.764785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history4 = model.fit(X_train, y_train, batch_size=16, epochs=5, verbose=1, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T15:01:31.484092Z","iopub.execute_input":"2021-11-17T15:01:31.484647Z","iopub.status.idle":"2021-11-17T21:30:57.15029Z","shell.execute_reply.started":"2021-11-17T15:01:31.48459Z","shell.execute_reply":"2021-11-17T21:30:57.147035Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
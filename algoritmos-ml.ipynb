{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Tabla de contenidos\n\n1. [**Importación de librerías**](#1.-Importación-de-librerías)   \n2. [**Cargo los datos**](#2.-Cargo-los-datos) \n3. [**Limpieza de los datos**](#3.-Limpieza-de-los-datos)  \n    3.1 [**Checkeo los duplicados**](#3.1-Checkeo-los-duplicados)  \n    3.2 [**Compruebo si existen reseñas vacías**](#3.2-Compruebo-si-existen-reseñas-vacías)  \n    3.3 [**Distribución de los datos**](#3.3-Distribución-de-los-datos)\n4. [**Preprocesamiento del texto**](#4.-Preprocesamiento-del-texto)  \n5. [**Normalización de los datos**](#5.-Normalización-de-los-datos)    \n    5.1 [**Normalizo el puntaje de las reseñas para que varíe entre 0 y 4**](#5.1-Normalizo-el-puntaje-de-las-reseñas-para-que-varíe-entre-0-y-4)  \n    5.2 [**Elimino columnas que no van a ser utilizadas**](#5.2-Elimino-columnas-que-no-van-a-ser-utilizadas)  \n    5.3 [**Elimino textos que pueden haber quedado vacíos luego de preprocesar el texto**](#5.3-Elimino-textos-que-pueden-haber-quedado-vacíos-luego-de-preprocesar-el-texto)   \n6. [**Extracción de características**](#6.-Extracción-de-características)   \n    6.1 [**Generación de vectores**](#6.1-Generación-de-vectores)  \n    6.2 [**Separo los datos en dos conjuntos: train y test (80/20)**](#6.2-Separo-los-datos-en-dos-conjuntos:-train-y-test-(80/20))\n7. [**Creación del modelo**](#7.-Creación-del-modelo)   \n    7.1 [**Regresión logística**](#7.1-Regresión-logística)  \n    7.2 [**SVM (Support Vector Machine)**](#7.2-SVM-(Support-Vector-Machine))  \n    7.2.1 [**SVM One-to-One**](#7.2.1-SVM-One-to-One)  \n    7.2.2 [**SVM One-to-Rest**](#7.2.2-SVM-One-to-Rest)  \n    7.3 [**Naive Bayes**](#7.3-Naive-Bayes)  \n    7.3.1 [**GaussianNB**](#7.3.1-GaussianNB)  \n    7.3.2 [**BernoulliNB**](#7.3.2-BernoulliNB)  \n    7.4 [**Random Forest**](#7.4-Random-Forest)  ","metadata":{}},{"cell_type":"markdown","source":"### 1. Importación de librerías","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport spacy\nimport seaborn as sns\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nimport re\nfrom bs4 import BeautifulSoup","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:09:20.916146Z","iopub.execute_input":"2021-11-19T00:09:20.916988Z","iopub.status.idle":"2021-11-19T00:09:23.573696Z","shell.execute_reply.started":"2021-11-19T00:09:20.916869Z","shell.execute_reply":"2021-11-19T00:09:23.572827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Cargo los datos","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/amazon-product-reviews/Reviews.csv\")\nprint(\"Tamaño de los datos: \", df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:15:06.909098Z","iopub.execute_input":"2021-11-19T00:15:06.909406Z","iopub.status.idle":"2021-11-19T00:15:15.482404Z","shell.execute_reply.started":"2021-11-19T00:15:06.909375Z","shell.execute_reply":"2021-11-19T00:15:15.481374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:15:15.484552Z","iopub.execute_input":"2021-11-19T00:15:15.484865Z","iopub.status.idle":"2021-11-19T00:15:15.508291Z","shell.execute_reply.started":"2021-11-19T00:15:15.484825Z","shell.execute_reply":"2021-11-19T00:15:15.507329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Limpieza de los datos","metadata":{}},{"cell_type":"markdown","source":"#### 3.1 Checkeo los duplicados","metadata":{}},{"cell_type":"code","source":"df=df.sort_values('ProductId', kind='quicksort', na_position='last')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:15:15.509695Z","iopub.execute_input":"2021-11-19T00:15:15.510107Z","iopub.status.idle":"2021-11-19T00:15:16.673892Z","shell.execute_reply.started":"2021-11-19T00:15:15.510068Z","shell.execute_reply":"2021-11-19T00:15:16.673245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df.drop_duplicates(subset={\"Text\"}, keep='first', inplace=False)\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:15:16.675273Z","iopub.execute_input":"2021-11-19T00:15:16.675872Z","iopub.status.idle":"2021-11-19T00:15:17.661976Z","shell.execute_reply.started":"2021-11-19T00:15:16.675839Z","shell.execute_reply":"2021-11-19T00:15:17.661159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.2 Compruebo si existen reseñas vacías","metadata":{}},{"cell_type":"code","source":"print(df['Text'].isnull().sum())\ndf['Score'].isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3.3 Distribución de los datos","metadata":{}},{"cell_type":"code","source":"df['Score'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:15:17.663256Z","iopub.execute_input":"2021-11-19T00:15:17.66349Z","iopub.status.idle":"2021-11-19T00:15:17.67408Z","shell.execute_reply.started":"2021-11-19T00:15:17.663464Z","shell.execute_reply":"2021-11-19T00:15:17.673434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,7))\nsns.countplot(df['Score'])\nplt.title(\"Distribución de la puntuación\")","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:15:17.675186Z","iopub.execute_input":"2021-11-19T00:15:17.675777Z","iopub.status.idle":"2021-11-19T00:15:17.973485Z","shell.execute_reply.started":"2021-11-19T00:15:17.675745Z","shell.execute_reply":"2021-11-19T00:15:17.972839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Preprocesamiento del texto","metadata":{}},{"cell_type":"code","source":"def decontract(text):\n    text = re.sub(r\"won\\'t\", \"will not\", text)\n    text = re.sub(r\"can\\'t\", \"can not\", text)\n    text = re.sub(r\"n\\'t\", \" not\", text)\n    text = re.sub(r\"\\'re\", \" are\", text)\n    text = re.sub(r\"\\'s\", \" is\", text)\n    text = re.sub(r\"\\'d\", \" would\", text)\n    text = re.sub(r\"\\'ll\", \" will\", text)\n    text = re.sub(r\"\\'t\", \" not\", text)\n    text = re.sub(r\"\\'ve\", \" have\", text)\n    text = re.sub(r\"\\'m\", \" am\", text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:15:17.974864Z","iopub.execute_input":"2021-11-19T00:15:17.975192Z","iopub.status.idle":"2021-11-19T00:15:17.982378Z","shell.execute_reply.started":"2021-11-19T00:15:17.975153Z","shell.execute_reply":"2021-11-19T00:15:17.981617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nnegative_stop_words = set(word for word in stop_words if \"n't\" in word or 'no' in word)\nstop_words = stop_words - negative_stop_words","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:15:21.372539Z","iopub.execute_input":"2021-11-19T00:15:21.373128Z","iopub.status.idle":"2021-11-19T00:15:21.384417Z","shell.execute_reply.started":"2021-11-19T00:15:21.373085Z","shell.execute_reply":"2021-11-19T00:15:21.383572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lemmatizer = WordNetLemmatizer()\ndef preprocess_text(review):\n    review = re.sub(r\"http\\S+\", \"\", review)             # removing website links\n    review = BeautifulSoup(review, 'lxml').get_text()   # removing html tags\n    review = decontract(review)                         # decontracting\n    review = re.sub(\"\\S*\\d\\S*\", \"\", review).strip()     # removing the words with numeric digits\n    review = re.sub('[^A-Za-z]+', ' ', review)          # removing non-word characters\n    review = review.lower()                             # converting to lower case\n    review = [word for word in review.split(\" \") if not word in stop_words] # removing stop words\n    review = [lemmatizer.lemmatize(token, \"v\") for token in review] #lemmatization\n    review = \" \".join(review)\n    review.strip()\n    return review\ndf['Text'] = df['Text'].apply(lambda x: preprocess_text(x))","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:15:23.358651Z","iopub.execute_input":"2021-11-19T00:15:23.35893Z","iopub.status.idle":"2021-11-19T00:20:11.13622Z","shell.execute_reply.started":"2021-11-19T00:15:23.358904Z","shell.execute_reply":"2021-11-19T00:20:11.135412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"En caso de que se quiera utilizar stemming en vez de lematización, se puede ejecutar la siguiente celda","metadata":{}},{"cell_type":"code","source":"from nltk.stem import SnowballStemmer\nstemmer = SnowballStemmer(language='english')\ndef preprocess_text(review):\n    review = re.sub(r\"http\\S+\", \"\", review)             # removing website links\n    review = BeautifulSoup(review, 'lxml').get_text()   # removing html tags\n    review = decontract(review)                         # decontracting\n    review = re.sub(\"\\S*\\d\\S*\", \"\", review).strip()     # removing the words with numeric digits\n    review = re.sub('[^A-Za-z]+', ' ', review)          # removing non-word characters\n    review = review.lower()                             # converting to lower case\n    review = [word for word in review.split(\" \") if not word in stop_words] # removing stop words\n    review = [stemmer.stem(token) for token in review] #stemming\n    review = \" \".join(review)\n    review.strip()\n    return review\ndf['Text'] = df['Text'].apply(lambda x: preprocess_text(x))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Text'].head()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:20:11.138Z","iopub.execute_input":"2021-11-19T00:20:11.138749Z","iopub.status.idle":"2021-11-19T00:20:11.145235Z","shell.execute_reply.started":"2021-11-19T00:20:11.138712Z","shell.execute_reply":"2021-11-19T00:20:11.144471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5. Normalización de los datos\n\n#### 5.1 Normalizo el puntaje de las reseñas para que varíe entre 0 y 4","metadata":{}},{"cell_type":"code","source":"def normalize(score):\n    return score - 1","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:20:11.146237Z","iopub.execute_input":"2021-11-19T00:20:11.146441Z","iopub.status.idle":"2021-11-19T00:20:11.159139Z","shell.execute_reply.started":"2021-11-19T00:20:11.146418Z","shell.execute_reply":"2021-11-19T00:20:11.158128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Score\"] = df[\"Score\"].apply(normalize)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:20:11.160893Z","iopub.execute_input":"2021-11-19T00:20:11.16117Z","iopub.status.idle":"2021-11-19T00:20:11.414934Z","shell.execute_reply.started":"2021-11-19T00:20:11.161134Z","shell.execute_reply":"2021-11-19T00:20:11.414087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.2 Elimino columnas que no van a ser utilizadas","metadata":{}},{"cell_type":"code","source":"df = df.drop(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time', 'Summary'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:20:11.416064Z","iopub.execute_input":"2021-11-19T00:20:11.416296Z","iopub.status.idle":"2021-11-19T00:20:11.435161Z","shell.execute_reply.started":"2021-11-19T00:20:11.416269Z","shell.execute_reply":"2021-11-19T00:20:11.434109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5.3 Elimino textos que pueden haber quedado vacíos luego de preprocesar el texto","metadata":{}},{"cell_type":"code","source":"df['Text'].replace('', np.nan, inplace=True)\ndf.dropna(subset=['Text'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:20:11.436593Z","iopub.execute_input":"2021-11-19T00:20:11.437036Z","iopub.status.idle":"2021-11-19T00:20:11.612715Z","shell.execute_reply.started":"2021-11-19T00:20:11.436979Z","shell.execute_reply":"2021-11-19T00:20:11.611878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.sample(frac=1).reset_index(drop=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:20:11.614078Z","iopub.execute_input":"2021-11-19T00:20:11.614298Z","iopub.status.idle":"2021-11-19T00:20:11.737829Z","shell.execute_reply.started":"2021-11-19T00:20:11.614273Z","shell.execute_reply":"2021-11-19T00:20:11.737029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6. Extracción de características","metadata":{}},{"cell_type":"markdown","source":"#### 6.1 Generación de vectores\n\nPara generar los vectores utilizaremos una funcionalidad que nos ofrece SpaCy de manera sencilla utilizando las word embeddings ya preentrenadas como word2vec y GloVe","metadata":{}},{"cell_type":"code","source":"nlp = spacy.load('en_core_web_lg')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:20:11.739313Z","iopub.execute_input":"2021-11-19T00:20:11.73953Z","iopub.status.idle":"2021-11-19T00:20:23.658134Z","shell.execute_reply.started":"2021-11-19T00:20:11.739506Z","shell.execute_reply":"2021-11-19T00:20:23.657268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with nlp.disable_pipes():\n    vectors = np.array([nlp(review.Text).vector for idx, review in df.iterrows()])\n    \nvectors.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:20:23.659259Z","iopub.execute_input":"2021-11-19T00:20:23.659581Z","iopub.status.idle":"2021-11-19T01:48:07.334236Z","shell.execute_reply.started":"2021-11-19T00:20:23.659549Z","shell.execute_reply":"2021-11-19T01:48:07.333229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Con las siguientes celdas se pueden guardar los vectores y el dataset procesado","metadata":{}},{"cell_type":"code","source":"from numpy import save\nsave('vectors.npy', vectors)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T19:23:22.42103Z","iopub.execute_input":"2021-11-10T19:23:22.421255Z","iopub.status.idle":"2021-11-10T19:23:22.858033Z","shell.execute_reply.started":"2021-11-10T19:23:22.42123Z","shell.execute_reply":"2021-11-10T19:23:22.857088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import load\nvectors = load('/kaggle/input/lemmatized/vectors.npy')","metadata":{"execution":{"iopub.status.busy":"2021-11-11T15:07:30.363029Z","iopub.execute_input":"2021-11-11T15:07:30.363373Z","iopub.status.idle":"2021-11-11T15:07:34.122178Z","shell.execute_reply.started":"2021-11-11T15:07:30.36334Z","shell.execute_reply":"2021-11-11T15:07:34.120971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('ReviewsLemmatized.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T19:23:22.85953Z","iopub.execute_input":"2021-11-10T19:23:22.859778Z","iopub.status.idle":"2021-11-10T19:23:27.697077Z","shell.execute_reply.started":"2021-11-10T19:23:22.859739Z","shell.execute_reply":"2021-11-10T19:23:27.696064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 6.2 Separo los datos en dos conjuntos: train y test (80/20)","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(vectors, df.Score, test_size=0.2, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T01:48:07.33873Z","iopub.execute_input":"2021-11-19T01:48:07.338952Z","iopub.status.idle":"2021-11-19T01:48:07.634836Z","shell.execute_reply.started":"2021-11-19T01:48:07.338927Z","shell.execute_reply":"2021-11-19T01:48:07.633923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7. Creación del modelo","metadata":{}},{"cell_type":"markdown","source":"#### 7.1 Regresión logística","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(max_iter=100000)\n\nlr.fit(X_train,y_train)\nprint(f'Model test accuracy: {lr.score(X_test, y_test)*100:.3f}%')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T01:48:07.636069Z","iopub.execute_input":"2021-11-19T01:48:07.63631Z","iopub.status.idle":"2021-11-19T01:54:53.852206Z","shell.execute_reply.started":"2021-11-19T01:48:07.636283Z","shell.execute_reply":"2021-11-19T01:54:53.851303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 7.2 SVM (Support Vector Machine)","metadata":{}},{"cell_type":"markdown","source":"##### 7.2.1 SVM One-to-One","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\nfrom sklearn.multiclass import OneVsOneClassifier\n\nmodel2 = OneVsOneClassifier(LinearSVC(random_state=1, dual=False))\nmodel2.fit(X_train, y_train)\n\nprint(f'Model test accuracy: {model2.score(X_test, y_test)*100:.3f}%')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T01:54:53.85396Z","iopub.execute_input":"2021-11-19T01:54:53.854446Z","iopub.status.idle":"2021-11-19T01:57:39.297768Z","shell.execute_reply.started":"2021-11-19T01:54:53.854406Z","shell.execute_reply":"2021-11-19T01:57:39.296838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 7.2.2 SVM One-to-Rest","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\nfrom sklearn.multiclass import OneVsRestClassifier\n\nmodel3 = OneVsRestClassifier(LinearSVC(random_state=1, dual=False))\nmodel3.fit(X_train, y_train)\n\nprint(f'Model test accuracy: {model3.score(X_test, y_test)*100:.3f}%')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T01:57:39.299465Z","iopub.execute_input":"2021-11-19T01:57:39.300374Z","iopub.status.idle":"2021-11-19T02:01:30.910425Z","shell.execute_reply.started":"2021-11-19T01:57:39.300316Z","shell.execute_reply":"2021-11-19T02:01:30.909559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 7.3 Naive Bayes","metadata":{}},{"cell_type":"markdown","source":"##### 7.3.1 GaussianNB","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)\n\nprint(f'Model test accuracy: {gnb.score(X_test, y_test)*100:.3f}%')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T02:01:30.912552Z","iopub.execute_input":"2021-11-19T02:01:30.913213Z","iopub.status.idle":"2021-11-19T02:01:32.780778Z","shell.execute_reply.started":"2021-11-19T02:01:30.913166Z","shell.execute_reply":"2021-11-19T02:01:32.779828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 7.3.2 BernoulliNB","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import BernoulliNB\n\nbnb = BernoulliNB()\nbnb.fit(X_train, y_train)\n\nprint(f'Model test accuracy: {bnb.score(X_test, y_test)*100:.3f}%')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T02:01:32.78317Z","iopub.execute_input":"2021-11-19T02:01:32.783908Z","iopub.status.idle":"2021-11-19T02:01:35.485879Z","shell.execute_reply.started":"2021-11-19T02:01:32.783864Z","shell.execute_reply":"2021-11-19T02:01:35.483218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 7.4 Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier(max_depth=2, random_state=0)\nclf.fit(X_train, y_train)\n\nprint(f'Model test accuracy: {clf.score(X_test, y_test)*100:.3f}%')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T02:01:35.487588Z","iopub.execute_input":"2021-11-19T02:01:35.488031Z","iopub.status.idle":"2021-11-19T02:04:14.870878Z","shell.execute_reply.started":"2021-11-19T02:01:35.48797Z","shell.execute_reply":"2021-11-19T02:04:14.870041Z"},"trusted":true},"execution_count":null,"outputs":[]}]}